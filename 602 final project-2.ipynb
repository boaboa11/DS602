{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071caf76-ad4b-408b-b806-ea7086b7b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from random import randint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5a78c3-c6ef-481e-a471-9bc14009ca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Model ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61     64044\n",
      "           1       0.38      0.47      0.42     35956\n",
      "\n",
      "    accuracy                           0.53    100000\n",
      "   macro avg       0.52      0.52      0.51    100000\n",
      "weighted avg       0.56      0.53      0.54    100000\n",
      "\n",
      "ROC AUC: 0.526856087757597\n",
      "\n",
      "=== Logistic Regression Model ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62     64044\n",
      "           1       0.42      0.56      0.48     35956\n",
      "\n",
      "    accuracy                           0.56    100000\n",
      "   macro avg       0.56      0.56      0.55    100000\n",
      "weighted avg       0.60      0.56      0.57    100000\n",
      "\n",
      "ROC AUC: 0.5865356807690041\n",
      "\n",
      "=== Random Forest Model ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.52      0.58     64044\n",
      "           1       0.38      0.52      0.44     35956\n",
      "\n",
      "    accuracy                           0.52    100000\n",
      "   macro avg       0.52      0.52      0.51    100000\n",
      "weighted avg       0.56      0.52      0.53    100000\n",
      "\n",
      "ROC AUC: 0.5306252980285365\n",
      "\n",
      "=== Random Guesser ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56     64044\n",
      "           1       0.36      0.50      0.42     35956\n",
      "\n",
      "    accuracy                           0.50    100000\n",
      "   macro avg       0.50      0.50      0.49    100000\n",
      "weighted avg       0.54      0.50      0.51    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To test \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from preprocessing import preprocess_data\n",
    "\n",
    "def production(X_path, y_path):\n",
    "    class TestModel:\n",
    "        def predict(self, X):\n",
    "            return [randint(0, 1) for _ in range(len(X))]\n",
    "\n",
    "    # Load model and scalers\n",
    "    best_xgb_clf = joblib.load('semisupervised_xgb_model.joblib')\n",
    "    best_lr = joblib.load('semisupervised_lr_model.joblib')\n",
    "    best_rf = joblib.load('semisupervised_rf_model.joblib')\n",
    "    scaler = joblib.load('scaler.joblib')\n",
    "    imputer = joblib.load('imputer.joblib')\n",
    "\n",
    "    # Load and preprocess data\n",
    "    df_X = pd.read_csv(X_path)\n",
    "    df_y = pd.read_csv(y_path)['Left']\n",
    "\n",
    "    X_scaled, _, _ = preprocess_data(df_X, imputer=imputer, scaler=scaler, fit=False)\n",
    "\n",
    "    # Predict with models\n",
    "    pred_xgb = best_xgb_clf.predict(X_scaled)\n",
    "    pred_lr = best_lr.predict(X_scaled)\n",
    "    pred_rf = best_rf.predict(X_scaled)\n",
    "    pred_random = TestModel().predict(X_scaled)\n",
    "\n",
    "    # Predict probabilities for ROC AUC\n",
    "    proba_xgb = best_xgb_clf.predict_proba(X_scaled)[:, 1]\n",
    "    proba_lr = best_lr.predict_proba(X_scaled)[:, 1]\n",
    "    proba_rf = best_rf.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"=== XGBoost Model ===\")\n",
    "    print(classification_report(df_y, pred_xgb))\n",
    "    print(\"ROC AUC:\", roc_auc_score(df_y, proba_xgb))\n",
    "\n",
    "    print(\"\\n=== Logistic Regression Model ===\")\n",
    "    print(classification_report(df_y, pred_lr))\n",
    "    print(\"ROC AUC:\", roc_auc_score(df_y, proba_lr))\n",
    "\n",
    "    print(\"\\n=== Random Forest Model ===\")\n",
    "    print(classification_report(df_y, pred_rf))\n",
    "    print(\"ROC AUC:\", roc_auc_score(df_y, proba_rf))\n",
    "\n",
    "    print(\"\\n=== Random Guesser ===\")\n",
    "    print(classification_report(df_y, pred_random))\n",
    "\n",
    "# Run the test\n",
    "production( \n",
    "\n",
    "  X_path='https://raw.githubusercontent.com/msaricaumbc/DS_data/master/ds602/final/employee_departure_dataset_X_prod.csv',\n",
    "\n",
    "  y_path='https://raw.githubusercontent.com/msaricaumbc/DS_data/master/ds602/final/employee_departure_dataset_y_prod.csv'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd3c1b-2d90-46de-b91c-7df1140418c1",
   "metadata": {},
   "source": [
    "### Metrics Selection for Predicting Employee Departure\n",
    "Employee departure prediction often involves **imbalanced data**, where the majority of employees stay. Therefore, standard accuracy is not sufficient. The following metrics are recommended:\n",
    "\n",
    "1. **ROC AUC**\n",
    "Evaluates the model’s ability to distinguish between “stay” and “leave” across all thresholds.\n",
    "2. **Precision (for 'Left')**\n",
    "Of all employees predicted to leave, how many actually left? Helps avoid false positives.\n",
    "3. **Recall (for 'Left')**\n",
    "Of all employees who actually left, how many did we correctly identify? Helps avoid false negatives.\n",
    "4. **F1-Score**\n",
    "The harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33361c-8955-41e1-a24f-e25d48f6c47e",
   "metadata": {},
   "source": [
    "### Conclusion why it didn't work- next steps\n",
    "The models show some ability to identify potential leavers, but the performance is barely better than chance. \n",
    "### The reasons might be **Limited Labeled Data and Weak Label Propagation**. \n",
    "Only 500 truly labeled samples were available from SME, which is extremely limited compared to the total dataset of 500,000 records. Although semi-supervised techniques like label propagation were used to expand the labeled set, such methods are highly sensitive to the quality and distribution of the initial labels. **Poor propagation** can lead to **incorrect pseudo-labels**, introducing significant noise into training. Given the massive imbalance between labeled and unlabeled data, and the potential inaccuracies introduced during propagation, the model's ability to generalize suffers considerably. This limitation is likely a key reason why even optimized models performed only marginally better than random guessing.\n",
    "### Next Steps\n",
    "1. Improve feature engineering further:\n",
    "\n",
    "Add domain-informed features (e.g., trend in reviews, salary change, project volatility).\n",
    "\n",
    "2. Improve label quality and coverage:\n",
    "\n",
    "Label more representative samples or get SME-labeled data beyond the 500 seeds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1ae47-1050-423c-9d53-c3acf967d2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
